{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workout Form Classification (Colab Clean Notebook)\n",
    "\n",
    "End-to-end pipeline for detecting proper vs improper execution across multiple strength exercises (10 classes total).\n",
    "\n",
    "Sections:\n",
    "1. Environment Setup (TensorFlow 2.16, Python 3.11)\n",
    "2. Project Code Acquisition / Sync\n",
    "3. Data Placement (raw videos) & Frame Extraction\n",
    "4. Dataset Assembly (arrays)\n",
    "5. Model Training (CNN+LSTM baseline)\n",
    "6. Evaluation & Quick Inference\n",
    "7. (Optional) Confusion Matrix & Per-Class Metrics\n",
    "8. Next Steps / Export\n",
    "\n",
    "Class taxonomy:\n",
    "- barbell_bicep_curl_(proper|improper)\n",
    "- bench_press_(proper|improper)\n",
    "- deadlift_(proper|improper)\n",
    "- plank_(proper|improper)\n",
    "- squat_(proper|improper)\n",
    "\n",
    "> Colab: Runtime â†’ Change runtime type â†’ Python 3.11 + GPU (T4/A100). Then run cells sequentially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment Setup\n",
    "import sys, platform\n",
    "print('Python:', sys.version)\n",
    "print('Platform:', platform.platform())\n",
    "\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q tensorflow==2.16.2 numpy<2.0 pandas<2.3 opencv-python pillow matplotlib moviepy scikit-learn\n",
    "\n",
    "import tensorflow as tf, numpy as np\n",
    "print('TF:', tf.__version__)\n",
    "print('GPUs:', tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print('Mixed precision enabled')\n",
    "else:\n",
    "    print('Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Code Acquisition\n",
    "Choose one method below to get the code into this Colab session.\n",
    "\n",
    "A) Public clone:\n",
    "```bash\n",
    "!git clone https://github.com/nikimanhanif/HaakimFYP.git\n",
    "%cd HaakimFYP\n",
    "```\n",
    "B) Private clone (replace TOKEN):\n",
    "```bash\n",
    "!git clone https://<TOKEN>@github.com/nikimanhanif/HaakimFYP.git\n",
    "%cd HaakimFYP\n",
    "```\n",
    "C) Google Drive (persistent):\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/HaakimFYP\n",
    "```\n",
    "After cloning, list files:\n",
    "```python\n",
    "import os\n",
    "print(os.listdir('.'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Placement & Frame Extraction\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "RAW = Path('data/raw')\n",
    "for split in ['train','val','test']:\n",
    "    (RAW / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Upload your workout videos into data/raw/train (and val/test).')\n",
    "print('Each filename should contain exercise + quality tokens, e.g. deadlift_proper_01.mp4, squat_wrong_set2.mp4')\n",
    "\n",
    "from stretch_detector.config import DEFAULT_CONFIG as cfg\n",
    "from stretch_detector.data.video_dataset import prepare_frames\n",
    "cfg.ensure_dirs()\n",
    "splits = prepare_frames(cfg)\n",
    "print({ 'train_videos': len(splits.train), 'val_videos': len(splits.val), 'test_videos': len(splits.test) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dataset Assembly (Arrays)\n",
    "from stretch_detector.data.video_dataset import build_arrays_for_split\n",
    "from stretch_detector.config import DEFAULT_CONFIG as cfg\n",
    "\n",
    "cfg.seq_len = 10\n",
    "cfg.image_size = (128,128)\n",
    "cfg.num_classes = 10\n",
    "\n",
    "X_train, y_train = build_arrays_for_split(cfg, 'train')\n",
    "X_val, y_val = build_arrays_for_split(cfg, 'val')\n",
    "print('Shapes -> X_train', X_train.shape, 'y_train', y_train.shape, 'X_val', X_val.shape, 'y_val', y_val.shape)\n",
    "\n",
    "assert X_train.shape[0] > 0, 'No training samples found. Ensure videos uploaded + frame extraction finished.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model Training (CNN+LSTM Baseline)\n",
    "import collections\n",
    "from tensorflow import keras\n",
    "from stretch_detector.models.cnn_lstm import build_cnn_lstm\n",
    "\n",
    "counts = collections.Counter(y_train.tolist())\n",
    "class_weight = {cls: max(1.0, float(sum(counts.values()))/(len(counts)*cnt)) for cls, cnt in counts.items()}\n",
    "print('Class counts:', dict(counts))\n",
    "print('Class weight:', class_weight)\n",
    "\n",
    "input_shape = (cfg.seq_len, cfg.image_size[0], cfg.image_size[1], cfg.channels)\n",
    "model = build_cnn_lstm(input_shape, num_classes=cfg.num_classes)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val) if X_val.shape[0] > 0 else None,\n",
    "    epochs=cfg.epochs,\n",
    "    batch_size=min(cfg.batch_size, max(1, X_train.shape[0])),\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "models_dir = Path('models'); models_dir.mkdir(exist_ok=True)\n",
    "model_path = models_dir / f'workout_form_cnn_lstm_{cfg.num_classes}cls.keras'\n",
    "model.save(model_path)\n",
    "print('Saved model to', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluation & Quick Inference\n",
    "from stretch_detector.data.video_dataset import class_key_from_label\n",
    "import numpy as np\n",
    "\n",
    "if X_val.shape[0] > 0:\n",
    "    metrics = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print('Validation:', dict(zip(model.metrics_names, metrics)))\n",
    "\n",
    "sample = X_train[0:1]\n",
    "pred = model.predict(sample, verbose=0)\n",
    "cls_id = int(np.argmax(pred, axis=-1)[0])\n",
    "print('Predicted class id:', cls_id, '->', class_key_from_label(cls_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Confusion Matrix & Per-Class Metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np, itertools\n",
    "from stretch_detector.data.video_dataset import COMBINED_CLASS_KEYS\n",
    "\n",
    "if X_val.shape[0] > 0:\n",
    "    val_preds = model.predict(X_val, verbose=0)\n",
    "    y_pred = np.argmax(val_preds, axis=-1)\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=range(cfg.num_classes))\n",
    "    print('Confusion Matrix:\\n', cm)\n",
    "    print('\\nClassification Report:\\n')\n",
    "    print(classification_report(y_val, y_pred, target_names=COMBINED_CLASS_KEYS[:cfg.num_classes]))\n",
    "else:\n",
    "    print('No validation set available; skipping metrics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps / Export\n",
    "- Increase `image_size` or `seq_len` for more temporal granularity (after confirming baseline works).\n",
    "- Try 3D CNN (`build_cnn3d`) for potentially richer temporal encoding.\n",
    "- Add data augmentation (random crop, brightness, slight rotation) via a tf.data pipeline.\n",
    "- Consider balancing strategies if improper samples are scarce.\n",
    "- Export to TFLite:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open('workout_form_model.tflite','wb').write(tflite_model)\n",
    "```\n",
    "- Download artifacts:\n",
    "```python\n",
    "from google.colab import files\n",
    "files.download(str(model_path))\n",
    "```\n",
    "- Persist to Drive (if mounted) for reuse.\n",
    "\n",
    "This notebook is now trimmed to only the workflow needed for workout form classification in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœ… Workout Form Classification on Colab (Updated 2025-09-21)\n",
    "\n",
    "This notebook now targets **multi-class workout form classification** (proper vs improper execution across multiple exercises) using the refactored Python package.\n",
    "\n",
    "**Pipeline covered:**\n",
    "1. Environment + dependencies (TensorFlow 2.16, Python 3.11)\n",
    "2. Project code acquisition (clone / Drive / upload)\n",
    "3. Raw workout video placement (train/val/test) and frame extraction\n",
    "4. Building supervised arrays (sequences of frames â†’ tensor)\n",
    "5. Training CNN+LSTM (or 3D CNN) to classify exercise + form quality\n",
    "6. Validation, quick inference, and model export\n",
    "\n",
    "> Runtime: Set Python = 3.11 and enable GPU for faster training.\n",
    "\n",
    "Classes (10): barbell_bicep_curl_(proper|improper), bench_press_(proper|improper), deadlift_(proper|improper), plank_(proper|improper), squat_(proper|improper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Environment Setup\n",
    "# Ensures Python 3.11 runtime, installs dependencies, and validates TensorFlow.\n",
    "import sys, platform, subprocess, textwrap\n",
    "print('Python version:', sys.version)\n",
    "print('Platform:', platform.platform())\n",
    "\n",
    "# Install core dependencies (avoid macOS-specific extras)\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q tensorflow==2.16.2 numpy<2.0 pandas<2.3 opencv-python pillow matplotlib moviepy\n",
    "\n",
    "import tensorflow as tf, numpy as np\n",
    "print('TF version:', tf.__version__)\n",
    "print('Num GPUs:', len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Optional: mixed precision if GPU present\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print('Mixed precision enabled')\n",
    "else:\n",
    "    print('Running on CPU - expect slower training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”„ Get the Project Code\n",
    "Choose ONE of the following methods:\n",
    "\n",
    "1. Public GitHub clone (recommended):\n",
    "```bash\n",
    "!git clone https://github.com/nikimanhanif/HaakimFYP.git\n",
    "%cd HaakimFYP\n",
    "```\n",
    "2. Private repo: Add a fine-grained token then:\n",
    "```bash\n",
    "!git clone https://<TOKEN>@github.com/nikimanhanif/HaakimFYP.git\n",
    "```\n",
    "3. Manual upload: Use Colab left pane â†’ Files â†’ Upload folder (not ideal for large data).\n",
    "4. Google Drive (persistent between sessions):\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Then: %cd /content/drive/MyDrive/HaakimFYP\n",
    "```\n",
    "\n",
    "After cloning / moving into project root, list files to verify:\n",
    "```python\n",
    "import os, itertools, textwrap\n",
    "print('\\n'.join(os.listdir('.')))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“‚ Dataset Placement & Frame Extraction (Workout Form)\n",
    "# Place your workout videos in data/raw/train, data/raw/val, data/raw/test.\n",
    "# Each video filename (or a parent folder name) should contain tokens that hint exercise + form quality\n",
    "# e.g. squat_proper_001.mp4, bench_wrong_session2.mp4 (aliases resolved automatically).\n",
    "import os, shutil, glob, json, sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "print('Project root:', PROJECT_ROOT)\n",
    "raw_root = PROJECT_ROOT / 'data' / 'raw'\n",
    "raw_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Raw split contents:')\n",
    "for split in ['train','val','test']:\n",
    "    d = raw_root / split\n",
    "    if d.exists():\n",
    "        vids = list(d.rglob('*'))\n",
    "        count = sum(1 for p in vids if p.is_file() and p.suffix.lower() in ['.mp4','.mov','.avi','.mkv','.mpeg','.mpg'])\n",
    "        print(f'  {split}: {count} video files (path={d})')\n",
    "    else:\n",
    "        print(f'  {split}: MISSING (create and upload videos)')\n",
    "\n",
    "from stretch_detector.config import DEFAULT_CONFIG as cfg\n",
    "from stretch_detector.data.video_dataset import prepare_frames\n",
    "cfg.ensure_dirs()\n",
    "splits = prepare_frames(cfg)\n",
    "print('Videos counted:', { 'train': len(splits.train), 'val': len(splits.val), 'test': len(splits.test) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª Build Arrays & Train (Workout Form Classifier)\n",
    "import numpy as np, math, collections\n",
    "from stretch_detector.data.video_dataset import build_arrays_for_split\n",
    "from stretch_detector.models.cnn_lstm import build_cnn_lstm\n",
    "from stretch_detector.models.cnn3d import build_cnn3d\n",
    "from stretch_detector.config import DEFAULT_CONFIG as cfg\n",
    "from tensorflow import keras\n",
    "\n",
    "# Core hyperparameters tailored for workout form clips\n",
    "cfg.seq_len = 10            # frames per sample\n",
    "cfg.image_size = (128,128)  # reduce for speed; increase to improve spatial detail\n",
    "cfg.batch_size = 8\n",
    "cfg.epochs = 15\n",
    "cfg.num_classes = 10        # 5 exercises Ã— 2 forms (proper/improper)\n",
    "\n",
    "X_train, y_train = build_arrays_for_split(cfg, 'train')\n",
    "X_val, y_val = build_arrays_for_split(cfg, 'val')\n",
    "print('Train shape:', X_train.shape, 'Val shape:', X_val.shape)\n",
    "\n",
    "if X_train.shape[0] == 0:\n",
    "    raise ValueError('No training samples found. Upload workout videos (proper/improper) then re-run extraction.')\n",
    "\n",
    "# Optional class weighting for imbalance\n",
    "counts = collections.Counter(y_train.tolist())\n",
    "class_weight = {cls: max(1.0, float(sum(counts.values()))/(len(counts)*cnt)) for cls, cnt in counts.items()}\n",
    "print('Class counts:', dict(counts))\n",
    "print('Derived class_weight:', class_weight)\n",
    "\n",
    "model_choice = 'cnn_lstm'  # switch to 'cnn3d' after verifying pipeline\n",
    "input_shape = (cfg.seq_len, cfg.image_size[0], cfg.image_size[1], cfg.channels)\n",
    "model = build_cnn_lstm(input_shape, num_classes=cfg.num_classes) if model_choice=='cnn_lstm' else build_cnn3d(input_shape, num_classes=cfg.num_classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val) if X_val.shape[0] > 0 else None,\n",
    "    epochs=cfg.epochs,\n",
    "    batch_size=min(cfg.batch_size, max(1, X_train.shape[0])),\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "models_dir = Path('models'); models_dir.mkdir(exist_ok=True)\n",
    "model_path = models_dir / f'workout_form_{model_choice}_{cfg.num_classes}cls.keras'\n",
    "model.save(model_path)\n",
    "print('Saved model to', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Evaluate & Quick Inference (Workout Form)\n",
    "import numpy as np\n",
    "from stretch_detector.data.video_dataset import class_key_from_label\n",
    "\n",
    "if 'X_val' in globals() and X_val.shape[0] > 0:\n",
    "    val_metrics = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print('Validation metrics:', dict(zip(model.metrics_names, val_metrics)))\n",
    "\n",
    "if X_train.shape[0] > 0:\n",
    "    sample = X_train[0:1]\n",
    "    pred = model.predict(sample, verbose=0)\n",
    "    cls_id = int(np.argmax(pred, axis=-1)[0])\n",
    "    print('Predicted class id:', cls_id, '->', class_key_from_label(cls_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Tips & Next Steps (Workout Form)\n",
    "- Reduce `cfg.seq_len` (e.g., 6) for faster iteration; increase when temporal nuances matter (e.g., deadlift phases).\n",
    "- Increase `image_size` (160â€“192) once pipeline is stable to capture bar path & limb positions.\n",
    "- Add data augmentation (future: random crop, slight brightness shifts) to generalize across gyms.\n",
    "- Track precision/recall per class by extending evaluation (confusion matrix) for proper vs improper forms.\n",
    "- Export to TFLite for mobile form feedback apps after pruning/quantization.\n",
    "- Download model: `from google.colab import files; files.download(str(model_path))`.\n",
    "\n",
    "Cleanup (optional):\n",
    "```python\n",
    "import shutil, pathlib\n",
    "for p in ['data/frames','data/npz']:\n",
    "    d=pathlib.Path(p)\n",
    "    if d.exists():\n",
    "        shutil.rmtree(d)\n",
    "```\n",
    "\n",
    "Next enhancement: replace raw frame stacking with a tf.data streaming loader + on-the-fly augmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
